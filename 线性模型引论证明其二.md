# 线性模型引论证明其二

## 4：参数估计

$$\begin{cases}
最小二乘估计\begin{cases}参数\beta的估计  \\误差方差\sigma^2的估计  \\正态线性模型  \\引入新的回归因子
\end{cases}  \\
约束最小二乘估计  \\
广义最小二乘估计  \\
最小二乘统一理论  \\
LS估计的稳健性  \\
估计的效率  \\
两步估计  \\
协方差改进法  \\
多元线性模型  \\
\end{cases}$$

### &emsp;4.1：最小二乘估计

**定理4.1.1**：$c'\beta$是可估函数$\Longleftrightarrow c\in \mathcal{M}(X')$

**推论4.1.1**：$c'\beta$是可估$\Longleftrightarrow c\in \mathcal{M}(X'X)$

**推论4.1.2**：对于任一可估函数$c'\beta$，$c'\hat\beta$是$c'\beta$的无偏估计，且$c'\hat\beta$与$(X'X)^-$的选择无关，即是惟一的

**定理4.1.2**：（Gauss-Markov定理）在模型中$y=X\beta+e,\quad E(e)=0,\quad Cov(e)=\sigma^2I_n$对任意的可估函数$c'\beta$，$LS$估计$c'\beta$为其惟一的$BLU$估计

**推论4.1.3**：设$\psi_i=c_i\beta,i=1,\cdots,k$都是可估函数，$\alpha_i,i=1,\cdots,k$是实数，则$\psi=\sum_{i=1}^k \alpha_i \psi_i$也是可估的，且$\hat\psi=\sum_{i=1}^k \alpha_i\hat\psi_i=\sum_{i=1}^k\alpha_i c'\hat\beta$是$\psi$的$BLU$估计

**推论4.1.4**：设$c'\beta$和$d'\beta$是两个可估函数，则
$$Var(c'\hat\beta)=\sigma^2c'(X'X)^-c$$
$$Cov(c'\beta,d'\beta)=\sigma^2c'(X'X)^-d$$
并且上述两式与所含广义逆选择无关

**定理4.1.3**：对于线性模型$y=X\beta+e,\quad E(e)=0,\quad Cov(e)=\sigma^2I_n$，$x\beta$必可估，且$X\hat\beta$是$X\beta$$BLU$估计

**定理4.1.4**：$\hat\sigma^2$是$\sigma^2$的无偏估计

**定理4.1.5**：对正态线性模型$y=X\beta+e,\quad e\sim N(0,\sigma^2I)$，设$c'\beta$为任一可估函数，则
（1）$LS$估计$c'\beta$的极大似然估计(maximum likelihood estimator)，且$c'\beta\sim N(c'\beta,\sigma^2c'(X'X)^-)$
（2）$\widetilde\sigma^2\triangleq\frac{n-r}{n}\sigma^2$为$\sigma^2$的$ML$估计，且$\frac{(n-r)\hat\sigma^2}{\sigma^2}\sim \chi_{n-r}^2$
（3）$c'\hat\beta$与$\hat\sigma^2$相互独立，这里$\hat\beta=(X'X)^-X'y，r=rk(x)$

**定理4.1.6**：对于正态线性模型$y=X\beta+e,\quad e\sim N(0,\sigma^2I)$
（1）$T_1=y'y$和$T_2=X'y$为完全充分统计量
（2）对任一可估函数$c'\beta$，$c'\hat\beta$为其惟一的最小方差无偏估计($minimun\ variance\ unbiased\ estimator$,MVU估计)

### &emsp;4.2 引入新的回归因子

**定理4.2.1**：对于模型$\begin{cases}y=X\beta +Z\gamma+\varepsilon=(X\vdots Z)\begin{pmatrix}\beta  \\ \gamma\end{pmatrix}+\varepsilon\triangleq\widetilde{X}\delta+\varepsilon  \\E(\varepsilon)=0,\quad Cov(\varepsilon)=\sigma^2I_n\end{cases}$，在条件$\mathcal{M}(X)\cap\mathcal{M}(Z)=\{0\}$和$rk(Z)=t$，记$M=I-Px$，$Px=X(X'X)^-X'$，$\widetilde{M}=I-P_{\widetilde x}$，$P_{\widetilde X}=\widetilde X(\widetilde X'\widetilde X)^-\widetilde X$，$L=(X'X)^-X'Z$，$\hat\delta=(\hat\beta'_G,\hat\gamma'_G)'$
（1）$c'\beta$可估$\Longleftrightarrow c\in\mathcal{M}(X')$；
（2）$\gamma$可估；
（3）$Z'MZ$可逆；

**定理4.2.2**
（1）$\hat\gamma_G=(Z'MZ)^{-1}Z'My$；
（2）$\hat\beta_G=(X'X)^-X'(y-Z\hat\gamma_G)=\hat\beta-L\hat\gamma_G$；
（3）$y'\widetilde My=(y-Z\hat\gamma_G)'M(y-Z\hat\gamma_G)=y'My-\hat\gamma_GZ'My$；
（4）对任一可估函数$c'\delta$
$$Var(c'\hat\delta)=\sigma^2 c'\begin{bmatrix}(X'X)^-+L(Z'MZ)^{-1}L'&-L(Z'MZ)^{-1}  \\-(Z'MZ)^{-1}L'&(Z'MZ)^{-1}\end{bmatrix}c$$
其中$\hat\beta=(X'X)^{-1}X'y$是扩充前模型中$\beta$的LS估计。

### 4.3：约束最小二乘估计

**定理4.3.1**：对带约束的线性模型$\begin{cases}y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2I_n  \\H\beta=0\end{cases}$，在约束$H\beta=0$下，$c'\beta$可估$\Longleftrightarrow c\in\mathcal{M}(X'\vdots H')$

**定理4.3.2**：联立方程组$\begin{bmatrix}X'X&H'\\H&0\end{bmatrix}\begin{bmatrix}\beta  \\\lambda\end{bmatrix}=\begin{bmatrix}X'y  \\0\end{bmatrix}$必有解，记它们的解为$\hat\beta_H$和$\hat\lambda_H$，且其任意解$\hat\beta_H$必为在约束条件下$H\beta=0$下的极小值

**定理4.3.3**：对带约束的线性模型$\begin{cases}y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2I_n  \\H\beta=0\end{cases}$，若$c'\beta$是约束可估的，则$c'\hat\beta_H$唯一，且$c'\hat\beta_H$为约束可估函数$c'\beta$在约束条件下$H\beta=0$下的唯一BLU估计。

**定理4.3.4**：对约束线性模型$\begin{cases}y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2I_n  \\H\beta=0\end{cases}$:
$$\hat\beta_H=C_1X'y=T^-X'y-T^-H'[HT^-H']^-HT^-X'y$$
其中$T=X'X+H'UH$，这里$U$为某个任意给定的对称阵。

**推论4.3.1**：对约束线性模型$\begin{cases}y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2I_n  \\H\beta=0\end{cases}$，当$\mathcal{M}(H')\subset\mathcal{M}(X')$时，
$$\begin{aligned}\hat\beta
&=C_1X'y=(X'X)^-X'y-(X'X)^-H'[H(X'X)^-H']^-H  \\
&=\hat\beta-(X'X)^-H'[H(X'X)^-H']^-H\hat\beta
\end{aligned}$$
其中$\hat\beta=(X'X)^-X'y$

**推论4.3.2**：对约束线性模型$\begin{cases}y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2I_n  \\H\beta=0\end{cases}$，当$\mathcal{M}(H')\subset\mathcal{M}(X')$，且$H$为行满秩矩阵时，
$$\hat\beta_H=\beta-(X'X)^-H'[H(X'X)^-H']^{-1}H\hat\beta$$
其中$\hat\beta=(X'X)^{-1}X'y$

**推论4.3.3**：对约束线性模型$\begin{cases}y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2I_n  \\H\beta=0\end{cases}$，当$\mathcal{M}(H')\subset\mathcal{M}(X')$，且$X$为列满秩矩阵，$H$为行满秩矩阵时：
$$\hat\beta_H=\hat\beta-(X'X)^{-1}H'[H(X'X)^{-1}H']^{-1}H\hat\beta$$
其中$\hat\beta=(X'X)^{-1}X'y$

**推论4.3.4**：对非齐次约束$H\beta=d$，当$\mathcal{M}(H')\subset\mathcal{M}(X')$时，
$$\hat\beta_H=\hat\beta-(X'X)^-H'[H(X'X)^-H']^-(H\hat\beta-d)$$
其中$\hat\beta=(X'X)^{-1}X'y$

**推论4.3.5**：若$\mathcal{M}(H')\subset\mathcal{M}(X')$，且$X$为列满秩，$H$为行满秩，则对非齐次约束$H\beta=d$，$\beta$的约束LS估计为
$$\hat\beta_H=\hat\beta-(X'X)^{-1}H'[H(X'X)^{-1}H']^{-1}(H\hat\beta-d)$$
其中$\hat\beta=(X'X)^{-1}X'y$

**定理4.3.5**：对线性模型$\begin{cases}y=X(I-H^-H)\gamma+e\triangleq\widetilde{X}\gamma+e  \\e\sim(0,\sigma^2 I_n)\end{cases}$，$\hat\sigma^2_H=\Vert y-X\hat\beta_H\Vert^2/(n-q)$是$\sigma^2$的一个无偏估计

**定理4.3.6**：对正态线性模型$y=X\beta+e,\quad e\sim N(0,\sigma^2 I)$约束条件$H\beta=0$下，设$c'\beta$为任一约束可估函数，则
（1）约束LS估计$c'\hat\beta_H$是$c'\beta$的约束ML估计
（2）$\widetilde\sigma^2_H\triangleq\frac{n-q}{n}\hat\sigma^2_H=\frac1n(y-X\widetilde\beta_H^2)'(y-X\hat\beta_H^2)$为$\sigma^2$的约束ML估计

### &emsp;4.3：广义最小二乘估计

**定理4.4.1**：设$\Sigma>0$且已知，对任一可估函数$c'\beta$，$c'\beta^*$为其惟一的的BLU估计，其方差为$\sigma^2c'(X'\Sigma^{-1}X)^-c$

**定理4.4.2**：$\sigma^{2*}$为$\sigma^2$的无偏估计

**定理4.4.3**：设$e\sim N(0,\sigma^2\Sigma),\Sigma>0$且已知，则
&emsp;（1）对任一可估函数$c'\beta$，$c'\beta^*$为$c'\beta$的ML估计，且$c'\beta^*\sim N(c'\beta,\sigma^2c(X'\Sigma^{-1}X)^-c)$
&emsp;（2）$\frac{n-r}{n}\sigma^{2*}$为$\sigma^2$的ML估计，且$(n-r)\sigma^2/\sigma^2\sim\chi_{n-r}^2$
&emsp;（3）$c'\beta^*$与$\sigma^{2*}$相互独立
&emsp;（4）当$rk(X_{n\times p})=p$时，$\beta^*$为$\beta$的ML估计，$\beta^*\sim N(\beta,\sigma^2(X'\Sigma^{-1}X)^{-1})$，且与$\sigma^{2*}$相互独立
&emsp;（5）若$c'\beta$可估，则$c'\beta^*$为其惟一的MVU估计
&emsp;（6）$\sigma^{2*}$为$\sigma^2$的惟一MVU估计

### &emsp;4.4：最小二乘统一理论

**引理4.5.1**：对于线性模型$y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2\Sigma$，不管$\Sigma>0$或$\Sigma\ge 0$，$y\in\mathcal{M}(\Sigma\vdots X)$总是成立

**引理4.5.2**：$T=\Sigma+XUX'$，其中$U$为任意给定的对称阵，且$rk(T)=rk(\Sigma\vdots X)$，其所定义的$T$，总有
&emsp;（1）$\mathcal{M}(T)=\mathcal{M}(\Sigma\vdots X)$
&emsp;（2）$X'T^-X$，$X'T^-y$和$(y-X\beta)T^-(y-X\beta)$都与广义逆$T^-$的选择无关
&emsp;（3）$\mathcal{M}(X'T^-X)=\mathcal{M}(X')$，且与$T^-$的选择无关

**引理4.5.3**：对于线性模型$y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2\Sigma$和任意可估函数$c'\beta$有
（1）$c'\beta^*=c'(X'T^-X)^-X'T^-y$为$c'\beta$的BLU估计
（2）$Var(c'\beta^*)=\sigma^2c'[(X'T^-X)^--U]c$

**推论4.5.1**：对于线性模型$y=X\beta+e,\quad E(e)=0,Cov(e)=\sigma^2\Sigma$，若$\mathcal{M}(X)\subset \mathcal{M}(\Sigma)$，则对任一可估函数$c'\beta$，其BLU估计为
&emsp;&emsp;&emsp;$\begin{aligned}&c'\beta^*=c'(X'\Sigma^-X)^-X'\Sigma^-y  \\ &Var(c'\beta^*)=\sigma^2 c'(X'\Sigma^-X)^-c\end{aligned}$
并且所有表达式与所包含的广义逆选择无关，特别，当$rk(X)=p$时，$\beta^*=(X'\Sigma^-X)^{-1}X'\Sigma^-y$为$\beta$的BLU估计，其协方差阵为$Cov(\beta^*)=\sigma^2(X'\Sigma^-X)^{-1}$

**定理4.5.2**：$\sigma^{2*}=(y-X\beta^*)'T^-(y-X\beta^*)/q$为$\sigma^2$的无偏估计，其中$q=rk(T)-rk(X)$

### &emsp;4.5:LS估计的稳健性

**定理4.6.1（LSE稳定性的充要条件）**：对于线性模型$y=X\beta+e,\quad E(e)=0,\quad Cov=\sigma^2\Sigma$，和任一可估函数$c'\beta$，$c'\hat\beta=c'\beta^*$成立当且仅当下列条件之一成立。
&emsp;&emsp;&emsp;$\begin{aligned}
&(1):X'\Sigma Z=0  \\
&(2):\Sigma=X\Lambda_1 X'+Z\Lambda_2Z'  \\
&(3):\Sigma=XD_1X'+ZD_2Z'+\sigma^2I
\end{aligned}$
其中$\Lambda_1$，$\Lambda_2$，$D_1$和$D_2$为任意对称阵，但使$\Sigma\ge0$

**推论4.6.1**：对于线性模型$y=X\beta+e,\quad E(e)=0,\quad Cov=\sigma^2\Sigma$，和任一可估函数$c'\beta$，$c'\hat\beta=c'\beta^*$成立当且仅当$\Sigma$可表示为$\Sigma=XD_1X'+ZD_2Z'+aI$，其中$a$为任一函数

**定理4.6.2**：对于线性模型$y=X\beta+e,\quad E(e)=0,\quad Cov=\sigma^2\Sigma$，和任一可估函数$c'\beta$，$c'\hat\beta=c'\beta^*$成立当且仅当下列条件之一成立。
（1）$\Sigma X=X\beta$对某矩阵$B$，即$\mathcal{M}(\Sigma X)\subseteq\mathcal{M}(X)$
（2）$\mathcal{M}(X)$由$\Sigma$的$r=rk(X)$个特征向量张成
（3）$P_X\Sigma$为对称阵，其中$P_X=X(X'X)^-X'$

### &emsp;4.6：估计的效率

### &emsp;4.7：两步估计(GLSE)

### &emsp;4.8：协方差改进法

**定理4.9.1**：设$\theta$为$p\times 1$位置参数，$T_1$和$T_2$分别为$p\times 1$和$q\times 1$统计量，且$E(T_1)=\theta$，$E(T_2)=0$，记$Cov(T_1,T_2)=\begin{pmatrix}\Sigma_{11}&\Sigma_{12}  \\\Sigma_{21}&\Sigma_{22}\end{pmatrix}\triangleq\Sigma$，假定$\Sigma=0$，$\Sigma_{12}\ne 0$。则在线性估计类$\mathcal{A}=\{T=A_1T_1+A_2T_2，A_1和A_2为非随机阵，E(T)=\theta\}$，$\theta$的BLU估计为$\theta^*=T_1-\Sigma_{12}\Sigma_{22}^{-1}T_2$，且$Cov(\theta^*)=\Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}\le\Sigma_{11}=Cov(T_1)$，称$\theta^*$为协方差改进估计

### &emsp;4.9：多元线性模型

## 5：假设检验

### &emsp;5.1：线性假设的检验

**定理5.1.1：（齐次线性假设下与检验统计量分布有关的结论）**
&emsp;对于正态线性模型$y=X\beta+e,\quad e\sim N_n(0,\sigma^2I)$，$rk(X)=r\le (n,p)$，且$H_{m\times p}\beta$是$m$个线性无关的可估函数，则
&emsp;（1）$H\hat\beta\sim N(H\beta,\sigma^2H(X'X)^-H')$，$S_e^2\sim\sigma^2\chi_{n-r}^2$，且$H\hat\beta$与$S_e^2$相互独立。
&emsp;（2）$S_{He}^2-S_e^2=(H\hat\beta)'(H(X'X)^-H')^{-1}(H\hat\beta)\sim\sigma^2\chi_{m,\delta}$，其中非中心参数$\delta=(H\beta)'(H(X'X)^-H')^{-1}(H\beta)/\sigma^2$
&emsp;（3）$S_{He}^2-S_e^2$与$S_e^2$相互独立
&emsp;（4）当线性假设$H\beta=0$为真时，$F\sim F_{m,n-r}$

**推论5.1.1：（非齐次线性假设下与检验统计量分布有关的结论）**
&emsp;对正态线性模型$y=X\beta+e,\quad e\sim N_n(0,\sigma^2I)$，$rk(X)=r\le (n,p)$，对于相容非齐次线性假设$H\beta=d$，$rk(H)=m$，$\mathcal{M}(H')\subset\mathcal{M}(X')$，有
&emsp;（1）$H\hat\beta\sim N(H\beta,\sigma^2H(X'X)^-H')$，$S_e^2\sim\sigma^2\chi_{n-r}^2$，且$H\hat\beta$与$S_e^2$相互独立
&emsp;（2）$S_{He}^2-S_e^2=(H\hat\beta-d)'(H(X'X)^-H')^{-1}(H\hat\beta-d)\sim\sigma^2\chi_{m,\delta}^2$，且与$S_e^2$相互独立，其非中心参数$\delta=(H\beta-d)'(H(X'X)^-H')^{-1}(H\beta-d)/\sigma^2$
&emsp;（3）当$H\beta=d$为真时
$$F=\frac{(H\hat\beta-d)'(H(X'X)^-H')^{-1}(H\hat\beta-d)/m}{S_e^2/(n-r)}\sim F_{m,n-r}$$
&emsp;&emsp;&emsp;&emsp;这里$r=rk(X)$

### 5.2：置信椭球和同时置信区间

**定理5.2.1**：对于正态线性模型$y=X\beta+e,\quad e\sim N_n(0,\sigma^2I)$，若$rk(H)=m$，$\mathcal{M}(H')\subset\mathcal{M}(X')$，即$H_{m\times m}\beta(rk(H)=m)$是可估函数，它的一切线性函数$b'H\beta$的置信系数为$1-\alpha$的同时置信区间为
$$b'H\hat\beta\pm\big[mb'VbF_{m,n-r}(\alpha)\big]^{1/2}\hat\sigma$$
其中$\hat\beta=(X'X)^-X'y$，$V=H(X'X)^-H'$

### 5.3：预测

**定理5.3.1**：对模型$y=X\beta+e,\quad E(e)=0,\quad Cov(e)=\sigma^2\Sigma$和$y_0=X_0\beta+\epsilon_0,\quad E(\epsilon_0)=0,\quad Cov(\epsilon_0)=\sigma^2\Sigma_0$，若$Cov(e,\epsilon_0)=\sigma^2V$，且$X_0\beta$在模型$y=X\beta+e,\quad E(e)=0,\quad Cov(e)=\sigma^2\Sigma$下可估，则$y_0$在广义预测均方误差意义下的BLUP为$\widetilde y_0=Cy=X_0\beta^*+V\Sigma^{-1}(y-X\beta^*)$，特别，当$V=0$时，BLUP为$y_0^*=X_0\beta^*=X_0(X'\Sigma^{-1}X)^-X'\Sigma^{-1}y$

**定理5.3.2**：对模型$y=X\beta+e,\quad E(e)=0,\quad Cov(e)=\sigma^2\Sigma$和$y_0=X_0\beta+\epsilon_0,\quad E(\epsilon_0)=0,\quad Cov(\epsilon_0)=\sigma^2\Sigma_0$，假设$Cov(e,\epsilon_0)=0$，$X_0\beta$在模型下可估，且$e$和$\epsilon$均服从多元正态分布，则
&emsp;（1）$y_{0i}(i=1,\cdots,m)$的置信系数不低于$1-\alpha$的$Bonferroni$型同时预测区间为
$$X_i'\beta^*\pm(mF_{m,n-r}(\alpha))^{1/2}\hat\sigma^2\Big(\sigma_{ii}^{(0)}+x_i'(X'\Sigma^{-1}X)^-x_i\Big)^{1/2},\quad i=1,\cdots,m$$
&emsp;（2）$y_{0i}(i=1,\cdots,m)$置信系数不低于$1-\alpha$的$Scheffe$型同时预测区间为
$$x_i'\beta^*\pm(mF_{m,n-r}(\alpha))^{1/2}\hat\sigma\Big(\sigma_{ii}^{(0)}+x_i'(X'\Sigma^{-1}X)^-x_i\Big)^{1/2},\quad i=1,\cdots,m$$